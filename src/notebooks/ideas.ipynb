{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ba2bcc",
   "metadata": {},
   "source": [
    "**add Gabor filters?** They could enhance edge detection. Here's what we could do:\n",
    "\n",
    "1. **Replace W pathway with Gabor bank** - Multiple orientations\n",
    "2. **Add Gabor as preprocessing** - Before the network\n",
    "3. **Add Gabor branch parallel to XYW** - Extra pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0068b4",
   "metadata": {},
   "source": [
    "Great questions! Let me analyze both concerns:\n",
    "\n",
    "## Will Gabor filters give better results?\n",
    "\n",
    "**Not guaranteed.** Here's why:\n",
    "\n",
    "| Aspect | W Pathway (Current) | Gabor Filters |\n",
    "|--------|---------------------|---------------|\n",
    "| **Learnable** | ✅ Yes - weights adapt to data | ❌ Fixed kernels (or partially learnable) |\n",
    "| **Orientations** | 2 (H + V only) | 4-8 typically (0°, 45°, 90°, 135°...) |\n",
    "| **Parameters** | Few (depthwise) | More if learnable |\n",
    "| **Edge types** | Horizontal + Vertical | Multi-orientation |\n",
    "\n",
    "**Gabor might help IF:**\n",
    "- Your dataset has many diagonal/curved edges\n",
    "- W pathway is underfitting directional info\n",
    "\n",
    "**Gabor might hurt IF:**\n",
    "- Fixed Gabor kernels don't match your edge statistics\n",
    "- Overfitting due to more parameters\n",
    "\n",
    "---\n",
    "\n",
    "## Training Cost Comparison\n",
    "\n",
    "```\n",
    "Current W Pathway:\n",
    "- 1×3 depthwise conv: inchannel × 1 × 3 = 3 × inchannel params\n",
    "- 3×1 depthwise conv: inchannel × 3 × 1 = 3 × inchannel params\n",
    "- Two 1×1 convs: ~2 × inchannel² params\n",
    "- Total: ~2×inchannel² + 6×inchannel\n",
    "\n",
    "Gabor Bank (8 orientations):\n",
    "- If FIXED: 0 learnable params (but 8× more compute per forward pass)\n",
    "- If LEARNABLE: 8 × kernel_size² × channels = much more params\n",
    "```\n",
    "\n",
    "| Approach | Params Increase | Compute Increase | Training Time |\n",
    "|----------|-----------------|------------------|---------------|\n",
    "| Fixed Gabor (8 orientations) | None | ~4× in W | +10-20% |\n",
    "| Learnable Gabor | +50-100% in W | ~4× in W | +30-50% |\n",
    "| Hybrid (fixed + learnable) | +25% in W | ~2× in W | +15-25% |\n",
    "\n",
    "---\n",
    "\n",
    "## My Recommendation\n",
    "\n",
    "**Don't replace W entirely.** Instead, try **Option 3: Add Gabor as parallel branch**:\n",
    "\n",
    "````python\n",
    "class GaborBank(nn.Module):\n",
    "    \"\"\"Fixed Gabor filter bank - no learnable params, just extra features\"\"\"\n",
    "    def __init__(self, in_channels, num_orientations=4):\n",
    "        super().__init__()\n",
    "        self.num_orientations = num_orientations\n",
    "        \n",
    "        # Create fixed Gabor kernels (not learnable)\n",
    "        kernels = self._create_gabor_kernels(ksize=5, sigma=1.5, lambd=4.0)\n",
    "        self.register_buffer('gabor_kernels', kernels)  # (num_orientations, 1, 5, 5)\n",
    "        \n",
    "        # Learnable 1x1 to combine Gabor responses\n",
    "        self.combine = nn.Conv2d(in_channels * num_orientations, in_channels, kernel_size=1)\n",
    "    \n",
    "    def _create_gabor_kernels(self, ksize=5, sigma=1.5, lambd=4.0):\n",
    "        import cv2\n",
    "        kernels = []\n",
    "        for theta in np.linspace(0, np.pi, self.num_orientations, endpoint=False):\n",
    "            kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, 0.5, 0)\n",
    "            kernel = kernel / kernel.sum()  # Normalize\n",
    "            kernels.append(torch.from_numpy(kernel).float())\n",
    "        return torch.stack(kernels).unsqueeze(1)  # (N, 1, H, W)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Apply each Gabor filter to each channel\n",
    "        responses = []\n",
    "        for i in range(self.num_orientations):\n",
    "            kernel = self.gabor_kernels[i:i+1].expand(C, 1, -1, -1)\n",
    "            resp = F.conv2d(x, kernel, padding=2, groups=C)\n",
    "            responses.append(resp)\n",
    "        \n",
    "        # Concatenate and combine\n",
    "        gabor_features = torch.cat(responses, dim=1)  # (B, C*num_orientations, H, W)\n",
    "        return self.combine(gabor_features)\n",
    "\n",
    "\n",
    "class XYWG_E(nn.Module):\n",
    "    \"\"\"XYW + Gabor End block (X + Y + W + G)\"\"\"\n",
    "    def __init__(self, inchannel, outchannel):\n",
    "        super().__init__()\n",
    "        self.x_c = Xc1x1(inchannel, outchannel)\n",
    "        self.y_c = Yc1x1(inchannel, outchannel)\n",
    "        self.w = W(inchannel, outchannel)\n",
    "        self.g = GaborBank(inchannel, num_orientations=4)  # NEW: Gabor branch\n",
    "        self.fuse = nn.Conv2d(outchannel + inchannel, outchannel, kernel_size=1)  # Fuse all\n",
    "\n",
    "    def forward(self, xc, yc, w):\n",
    "        x_out = self.x_c(xc)\n",
    "        y_out = self.y_c(yc)\n",
    "        w_out = self.w(w)\n",
    "        g_out = self.g(w)  # Gabor on same input as W\n",
    "        \n",
    "        # Fuse: X + Y + W, then concatenate Gabor and reduce\n",
    "        xyw = x_out + y_out + w_out\n",
    "        combined = torch.cat([xyw, g_out], dim=1)\n",
    "        return self.fuse(combined)\n",
    "````\n",
    "\n",
    "**Why this approach:**\n",
    "- ✅ Keeps W pathway (proven to work)\n",
    "- ✅ Adds Gabor multi-orientation info\n",
    "- ✅ Fixed Gabor = no extra learnable params\n",
    "- ✅ Only 1×1 conv to fuse = minimal overhead\n",
    "- ✅ Training cost increase: ~5-10%\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Test First\n",
    "\n",
    "Before implementing, let's check if W pathway is actually the bottleneck:\n",
    "\n",
    "```python\n",
    "# In your ablation study, check:\n",
    "# If \"Remove W\" shows small ODS drop → W is weak → Gabor might help\n",
    "# If \"Remove W\" shows large ODS drop → W is strong → Gabor may not help much\n",
    "```\n",
    "\n",
    "**What do your Ablation A results show for \"Remove W\"?** That will tell us if Gabor is worth adding."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
